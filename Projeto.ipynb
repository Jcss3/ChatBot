{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, MaxPooling1D, Dropout, Activation\n",
    "#from keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_1_train = pd.read_csv(\"dados/Atis_1/atis.train.csv\")\n",
    "atis_1_val = pd.read_csv(\"dados/Atis_1/atis.dev.csv\")\n",
    "atis_1_test = pd.read_csv(\"dados/Atis_1/atis.test.csv\")\n",
    "\n",
    "atis_2_train = pd.read_csv(\"dados/Atis_2/atis_intents_train.csv\")\n",
    "atis_2_test = pd.read_csv(\"dados/Atis_2/atis_intents_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atis 1:  (4274, 4)\n",
      "Atis 1:  (572, 4)\n",
      "Atis 1:  (586, 4)\n",
      "##############################\n",
      "Atis 2:  (4833, 2)\n",
      "Atis 2:  (799, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Atis 1: \",atis_1_train.shape)\n",
    "print(\"Atis 1: \",atis_1_val.shape)\n",
    "print(\"Atis 1: \",atis_1_test.shape)\n",
    "print(\"##############################\")\n",
    "print(\"Atis 2: \",atis_2_train.shape)\n",
    "print(\"Atis 2: \",atis_2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processamento dos Dados\n",
    "* Dataset a ser utilizado: <strong>Atis_1</strong>\n",
    "* Verificar  <strong>Intents</strong>\n",
    "* Verificar se existe algum <strong>valor Nan</strong>\n",
    "* Escolher colunas com <strong>Tokens(sentenças) e Intents</strong>\n",
    "* <strong>Eliminar</strong> caracter <strong>BOS</strong> do inicio das sentenças\n",
    "* <strong>Eliminar</strong> caracter <strong>EOS</strong> do final das sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>slots</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-00001</td>\n",
       "      <td>BOS what is the cost of a round trip flight fr...</td>\n",
       "      <td>O O O O O O O B-round_trip I-round_trip O O B-...</td>\n",
       "      <td>atis_airfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-00002</td>\n",
       "      <td>BOS now i need a flight leaving fort worth and...</td>\n",
       "      <td>O O O O O O O B-fromloc.city_name I-fromloc.ci...</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-00003</td>\n",
       "      <td>BOS i need to fly from kansas city to chicago ...</td>\n",
       "      <td>O O O O O O B-fromloc.city_name I-fromloc.city...</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             tokens  \\\n",
       "0  train-00001  BOS what is the cost of a round trip flight fr...   \n",
       "1  train-00002  BOS now i need a flight leaving fort worth and...   \n",
       "2  train-00003  BOS i need to fly from kansas city to chicago ...   \n",
       "\n",
       "                                               slots        intent  \n",
       "0  O O O O O O O B-round_trip I-round_trip O O B-...  atis_airfare  \n",
       "1  O O O O O O O B-fromloc.city_name I-fromloc.ci...   atis_flight  \n",
       "2  O O O O O O B-fromloc.city_name I-fromloc.city...   atis_flight  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_1_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atis_flight                 3173\n",
       "atis_airfare                 351\n",
       "atis_ground_service          207\n",
       "atis_airline                 139\n",
       "atis_abbreviation             94\n",
       "atis_aircraft                 70\n",
       "atis_quantity                 41\n",
       "atis_flight_time              38\n",
       "atis_capacity                 29\n",
       "atis_distance                 24\n",
       "atis_airport                  23\n",
       "atis_flight#atis_airfare      21\n",
       "atis_city                     18\n",
       "atis_ground_fare              18\n",
       "atis_flight_no                16\n",
       "atis_meal                      9\n",
       "atis_restriction               3\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_1_train['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Nan em train:\n",
      " id        0\n",
      "tokens    0\n",
      "slots     0\n",
      "intent    0\n",
      "dtype: int64\n",
      "#########################################################\n",
      "Valores Nan em val:\n",
      " id        0\n",
      "tokens    0\n",
      "slots     0\n",
      "intent    0\n",
      "dtype: int64\n",
      "#########################################################\n",
      "Valores Nan em test:\n",
      " id        0\n",
      "tokens    0\n",
      "slots     0\n",
      "intent    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores Nan em train:\\n\",atis_1_train.isnull().sum())\n",
    "print(\"#########################################################\")\n",
    "print(\"Valores Nan em val:\\n\",atis_1_val.isnull().sum())\n",
    "print(\"#########################################################\")\n",
    "print(\"Valores Nan em test:\\n\",atis_1_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_1_train = atis_1_train.loc[:,['tokens','intent']]\n",
    "atis_1_val = atis_1_val.loc[:,['tokens','intent']]\n",
    "atis_1_test = atis_1_test.loc[:,['tokens','intent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS what is the cost of a round trip flight fr...</td>\n",
       "      <td>atis_airfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS now i need a flight leaving fort worth and...</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS i need to fly from kansas city to chicago ...</td>\n",
       "      <td>atis_flight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens        intent\n",
       "0  BOS what is the cost of a round trip flight fr...  atis_airfare\n",
       "1  BOS now i need a flight leaving fort worth and...   atis_flight\n",
       "2  BOS i need to fly from kansas city to chicago ...   atis_flight"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_1_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando caracter indesejado do inicio BOS e final EOS sentenças\n",
    "atis_1_train['tokens'] = [x.replace('BOS ','') for x in atis_1_train['tokens']]\n",
    "atis_1_val['tokens'] = [x.replace('BOS ','') for x in atis_1_val['tokens']]\n",
    "atis_1_test['tokens'] = [x.replace('BOS ','') for x in atis_1_test['tokens']]\n",
    "\n",
    "atis_1_train['tokens'] = [x.replace(' EOS','') for x in atis_1_train['tokens']]\n",
    "atis_1_val['tokens'] = [x.replace(' EOS','') for x in atis_1_val['tokens']]\n",
    "atis_1_test['tokens'] = [x.replace(' EOS','') for x in atis_1_test['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Labels = {}\n",
    "count = 0\n",
    "for intent in atis_1_train['intent']:\n",
    "    if intent not in dict_Labels:\n",
    "        dict_Labels[intent] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atis_airfare': 0, 'atis_flight': 1, 'atis_abbreviation': 2, 'atis_ground_service': 3, 'atis_restriction': 4, 'atis_airport': 5, 'atis_quantity': 6, 'atis_meal': 7, 'atis_airline': 8, 'atis_city': 9, 'atis_flight_no': 10, 'atis_ground_fare': 11, 'atis_flight_time': 12, 'atis_flight#atis_airfare': 13, 'atis_distance': 14, 'atis_aircraft': 15, 'atis_capacity': 16}\n"
     ]
    }
   ],
   "source": [
    "print(dict_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_1_train['Label_intent'] = [dict_Labels[x] for x in atis_1_train['intent']]\n",
    "atis_1_val['Label_intent'] = [dict_Labels[x] for x in atis_1_val['intent']]\n",
    "atis_1_test['Label_intent'] = [dict_Labels[x] for x in atis_1_test['intent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>intent</th>\n",
       "      <th>Label_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the cost of a round trip flight from p...</td>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now i need a flight leaving fort worth and arr...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i need to fly from kansas city to chicago leav...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the meaning of meal code s</td>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>show me all flights from denver to pittsburgh ...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>show me all us air flights from atlanta to den...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>list the nonstop flights early tuesday morning...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>show me the flights from st. petersburg to tor...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i need a listing of flights from new york city...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>show me the flights on american airlines which...</td>\n",
       "      <td>atis_flight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens             intent  \\\n",
       "0  what is the cost of a round trip flight from p...       atis_airfare   \n",
       "1  now i need a flight leaving fort worth and arr...        atis_flight   \n",
       "2  i need to fly from kansas city to chicago leav...        atis_flight   \n",
       "3                 what is the meaning of meal code s  atis_abbreviation   \n",
       "4  show me all flights from denver to pittsburgh ...        atis_flight   \n",
       "5  show me all us air flights from atlanta to den...        atis_flight   \n",
       "6  list the nonstop flights early tuesday morning...        atis_flight   \n",
       "7  show me the flights from st. petersburg to tor...        atis_flight   \n",
       "8  i need a listing of flights from new york city...        atis_flight   \n",
       "9  show me the flights on american airlines which...        atis_flight   \n",
       "\n",
       "   Label_intent  \n",
       "0             0  \n",
       "1             1  \n",
       "2             1  \n",
       "3             2  \n",
       "4             1  \n",
       "5             1  \n",
       "6             1  \n",
       "7             1  \n",
       "8             1  \n",
       "9             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_1_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4274, 17)\n",
      "(572, 17)\n"
     ]
    }
   ],
   "source": [
    "atis_1_train_label_intent = atis_1_train['Label_intent']\n",
    "atis_1_train_label_intent = to_categorical(np.asarray(atis_1_train_label_intent))\n",
    "atis_1_val_label_intent = atis_1_val['Label_intent']\n",
    "atis_1_val_label_intent = to_categorical(np.asarray(atis_1_val_label_intent))\n",
    "print(atis_1_train_label_intent.shape)\n",
    "print(atis_1_val_label_intent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'to': 2, 'from': 3, 'flights': 4, 'the': 5, 'on': 6, 'flight': 7, 'me': 8, 'what': 9, 'show': 10, 'san': 11, 'boston': 12, 'a': 13, 'denver': 14, 'in': 15, 'francisco': 16, 'and': 17, 'i': 18, 'atlanta': 19, 'is': 20, 'dallas': 21, 'pittsburgh': 22, 'all': 23, 'list': 24, 'baltimore': 25, 'philadelphia': 26, 'like': 27, 'are': 28, 'airlines': 29, 'that': 30, 'washington': 31, 'of': 32, 'between': 33, 'please': 34, 'morning': 35, 'leaving': 36, 'pm': 37, 'would': 38, 'fly': 39, 'city': 40, 'for': 41, 'need': 42, 'fare': 43, 'wednesday': 44, 'first': 45, 'after': 46, 'there': 47, 'oakland': 48, 'trip': 49, 'ground': 50, 'arriving': 51, 'you': 52, 'cheapest': 53, 'which': 54, 'round': 55, 'transportation': 56, \"i'd\": 57, 'before': 58, 'does': 59, 'class': 60, 'with': 61, 'available': 62, 'st': 63, 'afternoon': 64, 'one': 65, 'milwaukee': 66, 'new': 67, 'have': 68, 'at': 69, 'way': 70, 'fares': 71, 'american': 72, 'dc': 73, 'give': 74, 'york': 75, 'leave': 76, 'thursday': 77, 'airport': 78, 'monday': 79, 'how': 80, 'tuesday': 81, 'want': 82, 'arrive': 83, 'nonstop': 84, 'information': 85, 'earliest': 86, 'chicago': 87, 'united': 88, 'vegas': 89, 'phoenix': 90, 'find': 91, 'las': 92, 'orlando': 93, 'miami': 94, 'go': 95, 'saturday': 96, 'can': 97, 'sunday': 98, 'twenty': 99, 'am': 100, 'toronto': 101, 'evening': 102, 'newark': 103, 'noon': 104, 'delta': 105, 'diego': 106, 'indianapolis': 107, 'seattle': 108, 'salt': 109, 'lake': 110, 'charlotte': 111, 'houston': 112, 'kansas': 113, 'any': 114, 'continental': 115, 'us': 116, 'air': 117, 'next': 118, 'august': 119, 'seventh': 120, 'friday': 121, 'memphis': 122, 'airline': 123, 'cleveland': 124, 'do': 125, 'fort': 126, 'worth': 127, 'los': 128, 'angeles': 129, 'july': 130, \"o'clock\": 131, \"what's\": 132, 'aircraft': 133, 'early': 134, 'stop': 135, 'downtown': 136, '5': 137, 'tell': 138, 'montreal': 139, '6': 140, 'june': 141, 'or': 142, 'louis': 143, 'cincinnati': 144, 'petersburg': 145, 'tampa': 146, 'minneapolis': 147, 'get': 148, 'tomorrow': 149, 'many': 150, 'detroit': 151, 'stopover': 152, 'an': 153, 'latest': 154, 'nashville': 155, 'going': 156, 'around': 157, 'departing': 158, 'cost': 159, '10': 160, 'about': 161, 'tacoma': 162, 'jose': 163, 'code': 164, 'by': 165, '8': 166, 'could': 167, 'may': 168, '7': 169, 'leaves': 170, 'type': 171, 'burbank': 172, 'service': 173, 'ticket': 174, 'much': 175, 'long': 176, 'mean': 177, 'expensive': 178, '12': 179, 'paul': 180, 'travel': 181, 'twa': 182, 'april': 183, 'california': 184, 'daily': 185, \"i'm\": 186, 'international': 187, 'depart': 188, 'coach': 189, 'columbus': 190, '4': 191, 'see': 192, 'beach': 193, 'dollars': 194, 'lowest': 195, 'northwest': 196, 'economy': 197, 'time': 198, 'book': 199, 'than': 200, 'okay': 201, 'night': 202, 'know': 203, 'least': 204, 'meal': 205, 'la': 206, 'used': 207, '9': 208, 'airports': 209, 'december': 210, 'return': 211, 'into': 212, 'last': 213, 'ontario': 214, 'november': 215, 'arrives': 216, 'flying': 217, 'westchester': 218, 'now': 219, 'day': 220, 'september': 221, 'less': 222, 'serve': 223, 'county': 224, 'eighth': 225, 'second': 226, 'as': 227, 'serves': 228, 'take': 229, 'it': 230, 'kind': 231, 'fifth': 232, 'schedule': 233, 'stopping': 234, 'capacity': 235, 'direct': 236, 'be': 237, 'love': 238, 'field': 239, 'dinner': 240, 'flies': 241, 'make': 242, 'seating': 243, 'looking': 244, 'car': 245, 'served': 246, 'stops': 247, 'general': 248, 'mitchell': 249, 'connecting': 250, 'breakfast': 251, 'sixth': 252, '2': 253, 'meals': 254, 'eastern': 255, 'ninth': 256, 'third': 257, 'possible': 258, 'out': 259, 'cities': 260, 'price': 261, 'airfare': 262, '3': 263, 'back': 264, 'has': 265, 'prices': 266, 'using': 267, 'will': 268, 'number': 269, 'goes': 270, 'tenth': 271, 'times': 272, 'plane': 273, 'business': 274, '1000': 275, 'this': 276, 'ua': 277, 'late': 278, 'display': 279, 'types': 280, 'most': 281, 'through': 282, 'limousine': 283, 'other': 284, 'your': 285, 'twentieth': 286, 'today': 287, 'two': 288, 'stand': 289, 'only': 290, 'week': 291, 'guardia': 292, '1991': 293, 'fifteenth': 294, 'thirtieth': 295, 'fourth': 296, 'wednesdays': 297, 'rental': 298, 'bwi': 299, 'via': 300, 'also': 301, 'then': 302, 'interested': 303, 'dl': 304, 'restriction': 305, 'twelfth': 306, 'same': 307, 'canadian': 308, 'midwest': 309, 'express': 310, 'listing': 311, 'ap': 312, 'numbers': 313, 'distance': 314, 'seventeenth': 315, 'either': 316, 'use': 317, 'classes': 318, 'should': 319, 'jersey': 320, 'sixteenth': 321, 'florida': 322, 'jfk': 323, 'smallest': 324, 'again': 325, 'far': 326, 'f': 327, 'tickets': 328, 'weekday': 329, 'layover': 330, 'north': 331, 'carolina': 332, '1': 333, 'my': 334, 'but': 335, 'people': 336, 'explain': 337, 'where': 338, 'october': 339, 'thirty': 340, 'their': 341, 'makes': 342, 'yes': 343, 'colorado': 344, 'shortest': 345, 'hi': 346, 'traveling': 347, 'arrangements': 348, 'stopovers': 349, 'returning': 350, 'rent': 351, 'eleventh': 352, 'hours': 353, 'when': 354, 'departure': 355, 'area': 356, 'midnight': 357, 'nineteenth': 358, 'm80': 359, 'offer': 360, 'transport': 361, 'y': 362, 'q': 363, 'qx': 364, 'abbreviation': 365, 'no': 366, 'arizona': 367, 'ohio': 368, 'tower': 369, '57': 370, 'mco': 371, 'dfw': 372, 'both': 373, 'january': 374, 'right': 375, 'under': 376, 'each': 377, 'if': 378, 'mornings': 379, 'thank': 380, 'lunch': 381, 'some': 382, 'over': 383, '11': 384, 'live': 385, 'alaska': 386, 'canada': 387, 'february': 388, \"i'll\": 389, 'codes': 390, 'during': 391, 'days': 392, 'logan': 393, 'minnesota': 394, 'taxi': 395, 'anywhere': 396, 'fourteenth': 397, '466': 398, 'airplane': 399, 'planes': 400, 'thrift': 401, 'lufthansa': 402, 'utah': 403, 'indiana': 404, 'serving': 405, '838': 406, 'these': 407, 'hp': 408, 'trips': 409, 'texas': 410, '1115': 411, '1245': 412, 'near': 413, 'sfo': 414, 'march': 415, 'those': 416, 'costs': 417, 'provided': 418, \"york's\": 419, 'passengers': 420, 'name': 421, 'sixteen': 422, 'more': 423, 'total': 424, 'boeing': 425, '72s': 426, 'uses': 427, '73s': 428, '757': 429, 'making': 430, 'eighteenth': 431, 'yn': 432, 'different': 433, 'pennsylvania': 434, 'quebec': 435, 'michigan': 436, \"let's\": 437, 'takeoffs': 438, 'landings': 439, 'coming': 440, 'qw': 441, 'h': 442, '747': 443, 'three': 444, 'dc10': 445, 'sometime': 446, 'saturdays': 447, '825': 448, 'ea': 449, 'close': 450, '230': 451, \"what're\": 452, '630': 453, 'starting': 454, '2100': 455, 'help': 456, 'cheap': 457, 'requesting': 458, 'following': 459, 'meaning': 460, 'restrictions': 461, 'connect': 462, 'options': 463, 'so': 464, 'maximum': 465, 'amount': 466, 'weekdays': 467, 'ten': 468, 'tennessee': 469, '530': 470, 'rates': 471, 'nationair': 472, '1992': 473, 'arrival': 474, 'f28': 475, 'ewr': 476, 'miles': 477, 'describe': 478, 'departures': 479, 'arrivals': 480, 'turboprop': 481, 'fit': 482, 'seats': 483, 'departs': 484, 'provide': 485, 'well': 486, 'services': 487, 'georgia': 488, 'fn': 489, 'trying': 490, 'include': 491, '270': 492, '296': 493, 'destination': 494, '281': 495, '555': 496, '1291': 497, 'co': 498, 'thursdays': 499, 'reservation': 500, \"we're\": 501, 'southwest': 502, 'ff': 503, '718': 504, 'originating': 505, 'choices': 506, 'six': 507, '1700': 508, 'wish': 509, '430': 510, 'noontime': 511, 'arrange': 512, 'plan': 513, 'hello': 514, 'later': 515, 's': 516, 'nevada': 517, 'cars': 518, '210': 519, '852': 520, 'still': 521, 'lastest': 522, '80': 523, '813': 524, 'without': 525, 'rentals': 526, 'ap80': 527, 'america': 528, 'west': 529, '300': 530, '1993': 531, '1994': 532, 'schedules': 533, '269': 534, '1039': 535, '1100': 536, 'repeat': 537, 'ord': 538, 'dca': 539, 'serviced': 540, 'names': 541, 'eight': 542, 'land': 543, 'various': 544, 'dulles': 545, '767': 546, '932': 547, '200': 548, 'along': 549, 'hold': 550, '733': 551, 'airplanes': 552, 'capacities': 553, 'd9s': 554, '505': 555, 'connections': 556, 'four': 557, 'who': 558, 'sure': 559, 'determine': 560, 'booking': 561, 'j31': 562, 'connection': 563, \"delta's\": 564, \"american's\": 565, 'aa': 566, 'too': 567, 'missouri': 568, 'great': 569, 'soon': 570, 'up': 571, 'm': 572, 'difference': 573, 'qo': 574, 'offers': 575, 'very': 576, '727': 577, '343': 578, '1110': 579, '1222': 580, '201': 581, '21': 582, '1500': 583, '217': 584, '3724': 585, 'takeoff': 586, 'nonstops': 587, '1200': 588, 'lives': 589, 'define': 590, 'stands': 591, 'ac': 592, '1145': 593, 'rate': 594, 'reservations': 595, 'look': 596, 'transcontinental': 597, 'month': 598, '720': 599, '934': 600, 'heading': 601, 'highest': 602, 'tuesdays': 603, \"sunday's\": 604, \"atlanta's\": 605, 'beginning': 606, '416': 607, 'ap68': 608, 'closest': 609, 'actually': 610, 'ls': 611, 'designate': 612, 'trans': 613, 'world': 614, '1030': 615, '1130': 616, '730': 617, 'sort': 618, 'fine': 619, 'belong': 620, 'snacks': 621, 'ever': 622, '382': 623, 'route': 624, 'longest': 625, 'red': 626, 'eye': 627, '20': 628, '497766': 629, '705': 630, 'straight': 631, 'another': 632, 'off': 633, 'oak': 634, 'atl': 635, '1220': 636, 'operation': 637, 'ap57': 638, 'lester': 639, 'pearson': 640, 'earlier': 641, '1017': 642, 'located': 643, 'zone': 644, '1850': 645, 'not': 646, 'exceeding': 647, '1505': 648, 'carries': 649, '428': 650, '755': 651, 'nights': 652, 'iah': 653, 'cvg': 654, 'bna': 655, 'mci': 656, 'hou': 657, 'lga': 658, 'lax': 659, 'yyz': 660, 'bur': 661, 'regarding': 662, 'largest': 663, 'greatest': 664, 'instead': 665, 'besides': 666, '1059': 667, 'advertises': 668, 'having': 669, '329': 670, '124': 671, 'equal': 672, '150': 673, '400': 674, 'l1011': 675, '734': 676, 'l10': 677, 'carried': 678, '100': 679, 'level': 680, \"that's\": 681, '163': 682, 'tonight': 683, 'hopefully': 684, 'itinerary': 685, '1940': 686, 'connects': 687, 'including': 688, 'preferably': 689, 'local': 690, 'combination': 691, 'run': 692, '1765': 693, 'come': 694, '320': 695, 'k': 696, 'dh8': 697, 'minimum': 698, 'intercontinental': 699, '459': 700, 'limousines': 701, 'train': 702, 'stapleton': 703, 'limo': 704, '82': 705, '139': 706, 'sounds': 707, 'grounds': 708, 'calling': 709, 'thereafter': 710, 'anything': 711, 'bring': 712, 'b': 713, 'qualify': 714, 'basis': 715, 'bh': 716, 'included': 717, 'whether': 718, 'offered': 719, 'being': 720, 'be1': 721, '737': 722, 'working': 723, 'scenario': 724, 'called': 725, 'd10': 726, 'includes': 727, 'travels': 728, 'snack': 729, 'supper': 730, 'reaches': 731, 'reaching': 732, 'vicinity': 733, 'good': 734, '1800': 735, 'overnight': 736, 'final': 737, 'summer': 738, '297': 739, 'listed': 740, '1055': 741, '405': 742, '315': 743, '486': 744, '1207': 745, '639': 746, '71': 747, '106': 748, '539': 749, '271': 750, '4400': 751, '3357': 752, '345': 753, '771': 754, '1209': 755, '212': 756, '257': 757, '608': 758, '746': 759, 'taking': 760, '311': 761, '417': 762, 'try': 763, 'inform': 764, 'kinds': 765, \"it's\": 766, '419': 767, 'let': 768, 'they': 769, 'kindly': 770, 'proper': 771, 'town': 772, 'kennedy': 773, '1230': 774, 'within': 775, 'friends': 776, 'visit': 777, 'here': 778, 'them': 779, '0900': 780, '1600': 781, \"one's\": 782, 'nighttime': 783, 'usa': 784, 'able': 785, 'put': 786, 'nw': 787, 'symbols': 788, 'kw': 789, 'sam': 790, 'wn': 791, 'sorry': 792, 'must': 793, '225': 794, '1158': 795, 'equipment': 796, '1205': 797, 'abbreviations': 798, 'jet': 799, 'companies': 800, 'continuing': 801, 'represented': 802, 'database': 803, 'single': 804, 'directly': 805, 'afterwards': 806, 'scheduled': 807, 'seat': 808, 'india': 809, 'buy': 810, 'say': 811, 'mealtime': 812, 'economic': 813, 'discount': 814, 'staying': 815, 'while': 816, 'across': 817, 'continent': 818, 'begins': 819, 'lands': 820, 'landing': 821, '110': 822, 'such': 823, '1045': 824, 'toward': 825, 'approximately': 826, '324': 827, '1300': 828, '723': 829, '1020': 830, '645': 831, 'inexpensive': 832, 'thing': 833, 'thanks': 834, 'question': 835, 'spend': 836, 'seventeen': 837, 'priced': 838, 'charges': 839, 'dinnertime': 840, '305': 841, '845': 842, '1026': 843, '823': 844, '2134': 845, '1024': 846, '130': 847, \"i've\": 848, 'got': 849, 'somebody': 850, 'else': 851, 'wants': 852, '420': 853, 'seven': 854, 'catch': 855, 'fifteen': 856, 'thirteenth': 857, 'midway': 858, 'oh': 859, \"don't\": 860, 'prefer': 861, 'comes': 862, 'mondays': 863, 'bound': 864, 'fridays': 865, \"friday's\": 866, 'sundays': 867, 'bay': 868, 'planning': 869, 'home': 870, 'reverse': 871, 'order': 872, 'philly': 873}\n"
     ]
    }
   ],
   "source": [
    "# Usar apenas as sentencas de treinameto\n",
    "# OOV para out of vocab\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(atis_1_train['tokens'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocab:  874  Tamanho da Sentenca:  259\n"
     ]
    }
   ],
   "source": [
    "def valor_maior_sentenca():\n",
    "    maior_sentenca_train = atis_1_train['tokens'].str.len().max()\n",
    "    maior_sentenca_val = atis_1_val['tokens'].str.len().max()\n",
    "    maior_sentenca_test = atis_1_test['tokens'].str.len().max()\n",
    "    maior_sentenca = max([maior_sentenca_train,maior_sentenca_test,maior_sentenca_val])\n",
    "    return maior_sentenca\n",
    "\n",
    "# tamanho do meu vocabulario voca_size adn 1 to unknow\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "# tamanho da maior sentenca dos dados originais\n",
    "maior_sentenca = valor_maior_sentenca()\n",
    "\n",
    "print(\"Tamanho do vocab: \",vocab_size,\" Tamanho da Sentenca: \",maior_sentenca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de treinamento:  \n",
      " [[  0   0   0 ...   6 168 252]\n",
      " [  0   0   0 ...  37 118  79]\n",
      " [  0   0   0 ...   5 459 220]\n",
      " ...\n",
      " [  0   0   0 ...  12  17  48]\n",
      " [  0   0   0 ...  32 607 194]\n",
      " [  0   0   0 ... 132 305 608]]\n",
      "Conjunto de validação:  \n",
      " [[  0   0   0 ... 350 168 252]\n",
      " [  0   0   0 ... 200 263  37]\n",
      " [  0   0   0 ...   5 220  46]\n",
      " ...\n",
      " [  0   0   0 ...  58 191  37]\n",
      " [  0   0   0 ...  15  31  73]\n",
      " [  0   0   0 ...  25   2  21]]\n",
      "Conjunto de teste:  \n",
      " [[  0   0   0 ... 350 119   1]\n",
      " [  0   0   0 ... 200 263  37]\n",
      " [  0   0   0 ...   5 459 220]\n",
      " ...\n",
      " [  0   0   0 ...   2  90 367]\n",
      " [  0   0   0 ...  15  31  73]\n",
      " [  0   0   0 ...  53 174 258]]\n"
     ]
    }
   ],
   "source": [
    "# Transformar as sentencas dos dados de treinamento e teste para sequencias numericas. ex [[1,2,6],[65,952,15,65],[1,2]]\n",
    "train_data_sentences = tokenizer.texts_to_sequences(atis_1_train['tokens'])\n",
    "val_data_sentences = tokenizer.texts_to_sequences(atis_1_val['tokens'])\n",
    "test_data_sentences = tokenizer.texts_to_sequences(atis_1_test['tokens'])\n",
    "\n",
    "# normalizar o tamnho das sequencias usando padding. ex [[0,1,2,6],[65,952,15,65],[0,0,1,2]]\n",
    "train_padded = pad_sequences(train_data_sentences, maxlen=maior_sentenca)\n",
    "val_padded = pad_sequences(val_data_sentences, maxlen=maior_sentenca)\n",
    "test_padded = pad_sequences(test_data_sentences, maxlen=maior_sentenca)\n",
    "\n",
    "print(\"Conjunto de treinamento: \",\"\\n\",train_padded[0:19])\n",
    "print(\"Conjunto de validação: \",\"\\n\",val_padded[0:19])\n",
    "print(\"Conjunto de teste: \",\"\\n\",test_padded[0:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the spacy model: nlp\n",
    "# nlp = spacy.load('en_core_web_md')\n",
    "#\n",
    "##tamnho do vocab\n",
    "#print(len(nlp.vocab.strings))\n",
    "#\n",
    "## dimension vector\n",
    "#print(nlp.vocab.vectors_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def valor_maior_sentenca():\n",
    "#    maior_sentenca_train = atis_1_train['tokens'].str.len().max()\n",
    "#    maior_sentenca_val = atis_1_val['tokens'].str.len().max()\n",
    "#    maior_sentenca_test = atis_1_test['tokens'].str.len().max()\n",
    "#    maior_sentenca = max([maior_sentenca_train,maior_sentenca_test,maior_sentenca_val])\n",
    "#    return maior_sentenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = 0\n",
    "#for key, vector in nlp.vocab.vectors.items():\n",
    "#    if nlp.vocab.strings[key] != None:\n",
    "#        count += 1\n",
    "#    #print(key, nlp.vocab.strings[key], vector[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## valores para o modelo deep learning\n",
    "#\n",
    "##vocab_size = len(nlp.vocab.strings)\n",
    "#vocab_size = count + 1\n",
    "#\n",
    "## tamanho da maior sentença - input_length\n",
    "#maior_sentenca = valor_maior_sentenca()\n",
    "#\n",
    "## embedding\n",
    "#embedding_dim = nlp.vocab.vectors_length\n",
    "#print(vocab_size)\n",
    "#print(embedding_dim)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar valor de encoding dos intents\n",
    "#def vetorizar_sentencas(sentencas,intents):\n",
    "#    # Calculate the length of sentences\n",
    "#    n_sentences = len(sentencas)\n",
    "#\n",
    "#    # Calculate the dimensionality of nlp\n",
    "#    embedding_dim = nlp.vocab.vectors_length\n",
    "#\n",
    "#    # Initialize the array with zeros: X\n",
    "#    sentencas_vetorizadas = np.zeros((n_sentences, embedding_dim))\n",
    "#\n",
    "#    # Iterate over the sentences\n",
    "#    for idx, sentence in enumerate(sentencas):\n",
    "#        # Pass each sentence to the nlp object to create a document\n",
    "#        doc = nlp(sentence)\n",
    "#        # Save the document's .vector attribute to the corresponding row in X\n",
    "#        sentencas_vetorizadas[idx, :] = doc.vector\n",
    "#\n",
    "#    # encoding intents\n",
    "#    count = 0\n",
    "#    # Iterate over the intents\n",
    "#    for intent_label in intents:\n",
    "#        if(intent_label not in dict_Labels):\n",
    "#            dict_Labels[intent_label] = count\n",
    "#            count += 1\n",
    "#\n",
    "#\n",
    "#    intents_encode = np.array([dict_Labels[x] for x in intents])\n",
    "#    \n",
    "#    return [sentencas_vetorizadas,intents_encode]\n",
    "#\n",
    "#train_vectors = vetorizar_sentencas(atis_1_train[\"tokens\"],atis_1_train['intent'])\n",
    "#val_vectors = vetorizar_sentencas(atis_1_val[\"tokens\"],atis_1_val['intent'])\n",
    "#test_vectors = vetorizar_sentencas(atis_1_test[\"tokens\"],atis_1_test['intent'])\n",
    "#\n",
    "##tf.keras.utils.to_categorical\n",
    "#train_sentencas_vetorizadas = train_vectors[0]\n",
    "#train_intent_label = to_categorical(train_vectors[1])\n",
    "#\n",
    "#val_sentencas_vetorizadas = val_vectors[0]\n",
    "#val_intent_label = to_categorical(val_vectors[1])\n",
    "#\n",
    "#test_sentencas_vetorizadas = test_vectors[0]\n",
    "#test_intent_label = to_categorical(test_vectors[1])\n",
    "#\n",
    "#print(\"Shape: \",train_sentencas_vetorizadas.shape,\" type: \",train_sentencas_vetorizadas.dtype)\n",
    "#print(\"Shape: \",train_intent_label.shape,\" type: \",train_intent_label.dtype)\n",
    "#print(\"Shape: \",val_sentencas_vetorizadas.shape,\" type: \",val_sentencas_vetorizadas.dtype)\n",
    "#print(\"Shape: \",val_intent_label.shape,\" type: \",val_intent_label.dtype)\n",
    "#print(\"Shape: \",test_sentencas_vetorizadas.shape,\" type: \",test_sentencas_vetorizadas.dtype)\n",
    "#print(\"Shape: \",test_intent_label.shape,\" type: \",test_intent_label.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = maior_sentenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size,embedding_dim, input_length=maior_sentenca))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(Dense(150, activation='sigmoid'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Dense(50, activation='relu'))\n",
    "#model1.add(Dense(25, activation='relu'))\n",
    "model1.add(Dense(17, activation='softmax'))\n",
    "\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 259, 259)          226366    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 259)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               39000     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                867       \n",
      "=================================================================\n",
      "Total params: 273,783\n",
      "Trainable params: 273,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 1.3018 - accuracy: 0.7052 - val_loss: 1.1457 - val_accuracy: 0.7395\n",
      "Epoch 2/50\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 1.1441 - accuracy: 0.7424 - val_loss: 1.1376 - val_accuracy: 0.7395\n",
      "Epoch 3/50\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 1.1283 - accuracy: 0.7424 - val_loss: 1.1204 - val_accuracy: 0.7395\n",
      "Epoch 4/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 1.0910 - accuracy: 0.7424 - val_loss: 1.0516 - val_accuracy: 0.7395\n",
      "Epoch 5/50\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9869 - accuracy: 0.7424 - val_loss: 0.9444 - val_accuracy: 0.7395\n",
      "Epoch 6/50\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.8732 - accuracy: 0.7532 - val_loss: 0.8893 - val_accuracy: 0.7535\n",
      "Epoch 7/50\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7925 - accuracy: 0.7824 - val_loss: 0.7933 - val_accuracy: 0.7727\n",
      "Epoch 8/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.7390 - accuracy: 0.7960 - val_loss: 0.7520 - val_accuracy: 0.7867\n",
      "Epoch 9/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.6978 - accuracy: 0.8072 - val_loss: 0.7242 - val_accuracy: 0.8077\n",
      "Epoch 10/50\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.6675 - accuracy: 0.8149 - val_loss: 0.6992 - val_accuracy: 0.8182\n",
      "Epoch 11/50\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6529 - accuracy: 0.8170 - val_loss: 0.6903 - val_accuracy: 0.8234\n",
      "Epoch 12/50\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.6279 - accuracy: 0.8273 - val_loss: 0.6795 - val_accuracy: 0.8217\n",
      "Epoch 13/50\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.6096 - accuracy: 0.8304 - val_loss: 0.6582 - val_accuracy: 0.8217\n",
      "Epoch 14/50\n",
      "134/134 [==============================] - 11s 86ms/step - loss: 0.5868 - accuracy: 0.8336 - val_loss: 0.6626 - val_accuracy: 0.8252\n",
      "Epoch 15/50\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.5847 - accuracy: 0.8372 - val_loss: 0.6462 - val_accuracy: 0.8217\n",
      "Epoch 16/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.5672 - accuracy: 0.8374 - val_loss: 0.6423 - val_accuracy: 0.8217\n",
      "Epoch 17/50\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5583 - accuracy: 0.8430 - val_loss: 0.6288 - val_accuracy: 0.8339\n",
      "Epoch 18/50\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.5375 - accuracy: 0.8472 - val_loss: 0.6237 - val_accuracy: 0.8322\n",
      "Epoch 19/50\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.5289 - accuracy: 0.8519 - val_loss: 0.6194 - val_accuracy: 0.8357\n",
      "Epoch 20/50\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.5210 - accuracy: 0.8533 - val_loss: 0.6061 - val_accuracy: 0.8339\n",
      "Epoch 21/50\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.5055 - accuracy: 0.8563 - val_loss: 0.6102 - val_accuracy: 0.8497\n",
      "Epoch 22/50\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.4990 - accuracy: 0.8587 - val_loss: 0.5812 - val_accuracy: 0.8514\n",
      "Epoch 23/50\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.4778 - accuracy: 0.8634 - val_loss: 0.5774 - val_accuracy: 0.8566\n",
      "Epoch 24/50\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.4609 - accuracy: 0.8680 - val_loss: 0.5600 - val_accuracy: 0.8584\n",
      "Epoch 25/50\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.4431 - accuracy: 0.8741 - val_loss: 0.5521 - val_accuracy: 0.8671\n",
      "Epoch 26/50\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.4189 - accuracy: 0.8821 - val_loss: 0.5312 - val_accuracy: 0.8689\n",
      "Epoch 27/50\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.4148 - accuracy: 0.8814 - val_loss: 0.5477 - val_accuracy: 0.8654\n",
      "Epoch 28/50\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.4102 - accuracy: 0.8809 - val_loss: 0.5439 - val_accuracy: 0.8671\n",
      "Epoch 29/50\n",
      "134/134 [==============================] - 4s 32ms/step - loss: 0.3885 - accuracy: 0.8865 - val_loss: 0.5179 - val_accuracy: 0.8724\n",
      "Epoch 30/50\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.3819 - accuracy: 0.8900 - val_loss: 0.5852 - val_accuracy: 0.8636\n",
      "Epoch 31/50\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.3830 - accuracy: 0.8914 - val_loss: 0.5086 - val_accuracy: 0.8689\n",
      "Epoch 32/50\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.3677 - accuracy: 0.8882 - val_loss: 0.5135 - val_accuracy: 0.8776\n",
      "Epoch 33/50\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.3586 - accuracy: 0.8975 - val_loss: 0.4998 - val_accuracy: 0.8794\n",
      "Epoch 34/50\n",
      "134/134 [==============================] - 5s 36ms/step - loss: 0.3495 - accuracy: 0.8978 - val_loss: 0.5033 - val_accuracy: 0.8794\n",
      "Epoch 35/50\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3426 - accuracy: 0.8996 - val_loss: 0.4911 - val_accuracy: 0.8794\n",
      "Epoch 36/50\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.3286 - accuracy: 0.9038 - val_loss: 0.4763 - val_accuracy: 0.8881\n",
      "Epoch 37/50\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.3240 - accuracy: 0.9076 - val_loss: 0.4814 - val_accuracy: 0.8846\n",
      "Epoch 38/50\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.3132 - accuracy: 0.9073 - val_loss: 0.5302 - val_accuracy: 0.8776\n",
      "Epoch 39/50\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.3119 - accuracy: 0.9064 - val_loss: 0.4791 - val_accuracy: 0.8846\n",
      "Epoch 40/50\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.3034 - accuracy: 0.9099 - val_loss: 0.4864 - val_accuracy: 0.8899\n",
      "Epoch 41/50\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2881 - accuracy: 0.9106 - val_loss: 0.4683 - val_accuracy: 0.8899\n",
      "Epoch 42/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.2891 - accuracy: 0.9137 - val_loss: 0.4671 - val_accuracy: 0.8969\n",
      "Epoch 43/50\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2828 - accuracy: 0.9132 - val_loss: 0.4776 - val_accuracy: 0.8899\n",
      "Epoch 44/50\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2741 - accuracy: 0.9219 - val_loss: 0.4663 - val_accuracy: 0.8951\n",
      "Epoch 45/50\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.2729 - accuracy: 0.9172 - val_loss: 0.4615 - val_accuracy: 0.8986\n",
      "Epoch 46/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.2653 - accuracy: 0.9174 - val_loss: 0.4705 - val_accuracy: 0.9003\n",
      "Epoch 47/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.2627 - accuracy: 0.9181 - val_loss: 0.4679 - val_accuracy: 0.9038\n",
      "Epoch 48/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.2577 - accuracy: 0.9207 - val_loss: 0.4594 - val_accuracy: 0.9003\n",
      "Epoch 49/50\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.2574 - accuracy: 0.9244 - val_loss: 0.4653 - val_accuracy: 0.9003\n",
      "Epoch 50/50\n",
      "134/134 [==============================] - 5s 37ms/step - loss: 0.2430 - accuracy: 0.9268 - val_loss: 0.4509 - val_accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "history1 = model1.fit(train_padded, atis_1_train_label_intent,\n",
    "                      validation_data=(val_padded, atis_1_val_label_intent),\n",
    "                      epochs=num_epochs,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 2s 19ms/step - loss: 0.2145 - accuracy: 0.9378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2144516110420227, 0.9377632141113281]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(train_padded,atis_1_train_label_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4509 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4509293735027313, 0.9090909361839294]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(val_padded,atis_1_val_label_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3694 - accuracy: 0.8942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36935991048812866, 0.894197940826416]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis_1_test_label_intent = atis_1_test['Label_intent']\n",
    "atis_1_test_label_intent = to_categorical(np.asarray(atis_1_test_label_intent))\n",
    "\n",
    "model1.evaluate(test_padded,atis_1_test_label_intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving\n",
    "* tokenizer\n",
    "* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# saving\n",
    "with open('recursos/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#\n",
    "#model1.save('../recursos/my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = 'recursos/my_model.h5'\n",
    "#\n",
    "#model1.save(model1, filepath)\n",
    "#\n",
    "#tf.keras.models.save_model(\n",
    "#    model1, filepath , overwrite=True, include_optimizer=True, save_format=None,\n",
    "#    signatures=None\n",
    "#)\n",
    "##https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicao =  model1.predict(test_padded)\n",
    "#count = 1\n",
    "#for elemento in predicao[:10]:\n",
    "#    print(\"Sentença {} \".format(count),\"\\nPredição {}: \".format(count),elemento)\n",
    "#    print(\"Best value of confidence: {}\".format(np.argmax(elemento)))\n",
    "#    print(\"Intent da Sentença: {}\".format(inv_dict_labels[np.argmax(elemento)]))\n",
    "#    print(\"\\n\")\n",
    "#    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliando modelo com conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atis_flight',\n",
       " 'atis_flight',\n",
       " 'atis_flight',\n",
       " 'atis_abbreviation',\n",
       " 'atis_flight']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função pare test\n",
    "def Predicao_Labels(sentenca_codificada):\n",
    "    # inverter o dicionario dict_labels para retornar o intent pelo seu valor chave inteiro\n",
    "    inv_dict_labels = {v: k for k, v in dict_Labels.items()}\n",
    "    #print(inv_dict_labels)\n",
    "    # passar a sentenca codificada\n",
    "    predicao = model1.predict([sentenca_codificada])\n",
    "    #print(predicao)\n",
    "    \n",
    "    intent_value = [inv_dict_labels[np.argmax(x)] for x in predicao]\n",
    "    \n",
    "    return intent_value\n",
    "\n",
    "# lista com valores da predicao\n",
    "Predicao_Labels(test_padded)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.894198\n"
     ]
    }
   ],
   "source": [
    "test_labels = np.array(atis_1_test['intent'])\n",
    "# Acurácia nos dados de test\n",
    "from sklearn.metrics import accuracy_score # importando a biblioteca para calcular a acurácia\n",
    "acuracia = accuracy_score(test_labels,np.array(Predicao_Labels(test_padded)))\n",
    "print('Acurácia: %f' % acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "       atis_abbreviation       0.71      0.62      0.67        16\n",
      "           atis_aircraft       0.21      0.50      0.30         8\n",
      "            atis_airfare       0.82      0.93      0.87        54\n",
      "            atis_airline       0.48      0.56      0.51        18\n",
      "            atis_airport       0.00      0.00      0.00         4\n",
      "           atis_capacity       0.50      0.75      0.60         4\n",
      "               atis_city       0.00      0.00      0.00         3\n",
      "           atis_distance       1.00      0.67      0.80         3\n",
      "             atis_flight       0.97      0.97      0.97       424\n",
      "atis_flight#atis_airfare       0.00      0.00      0.00         3\n",
      "          atis_flight_no       0.00      0.00      0.00         2\n",
      "        atis_flight_time       0.33      0.14      0.20         7\n",
      "        atis_ground_fare       0.67      0.50      0.57         4\n",
      "     atis_ground_service       0.96      0.93      0.95        29\n",
      "               atis_meal       0.00      0.00      0.00         1\n",
      "           atis_quantity       0.80      0.80      0.80         5\n",
      "        atis_restriction       0.00      0.00      0.00         1\n",
      "\n",
      "                accuracy                           0.89       586\n",
      "               macro avg       0.44      0.43      0.43       586\n",
      "            weighted avg       0.89      0.89      0.89       586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels,np.array(Predicao_Labels(test_padded))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Intent de Senteça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent de sentenças\n",
    "def Intent(sentenca,modelo):\n",
    "    \n",
    "    # loading model and tokenizer\n",
    "    with open('recursos/tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "        \n",
    "    # load model not working\n",
    "    #filepath = '../recursos/my_model.h5'\n",
    "    #model = tf.saved_model.load(filepath)\n",
    "    \n",
    "    # codificar a sentenca\n",
    "\n",
    "    sentenca = [sentenca]\n",
    "    sentenca_encoded = tokenizer.texts_to_sequences(sentenca)\n",
    "    sentenca_padded = pad_sequences(sentenca_encoded)\n",
    "    #print(sentenca_padded)\n",
    "    #intent = Predicao_Labels(sentenca_padded)\n",
    "    \n",
    "    #Inverter dict_labels para poder pegar o intent \n",
    "    inv_dict_labels = {v: k for k, v in dict_Labels.items()}\n",
    "    \n",
    "    # Predicao de intent apartir da sentenca codificada e o modelo\n",
    "    predicao = modelo.predict(sentenca_padded)\n",
    "    intent_value = [inv_dict_labels[np.argmax(x)] for x in predicao]\n",
    "    \n",
    "    return intent_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atis_flight']\n",
      "['atis_ground_service']\n",
      "['atis_airfare']\n"
     ]
    }
   ],
   "source": [
    "sentenca1='I want a list of the flights from Boston to DC'\n",
    "sentenca2='Are there any airports nearby?'\n",
    "sentenca3='fares from DC to NY'\n",
    "print(Intent(sentenca1,model1))\n",
    "print(Intent(sentenca2,model1))\n",
    "print(Intent(sentenca3,model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent Respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greet': re.compile('hello|hi|hey'), 'goodbye': re.compile('bye|farewell'), 'thankyou': re.compile('thank|thx')}\n",
      "{'default': 'default message', 'goodbye': 'goodbye for now', 'greet': 'Hello you! :)', 'thankyou': 'you are very welcome'}\n",
      "{'atis_airfare': [], 'atis_flight': [], 'atis_abbreviation': [], 'atis_ground_service': [], 'atis_restriction': [], 'atis_airport': [], 'atis_quantity': [], 'atis_meal': [], 'atis_airline': [], 'atis_city': [], 'atis_flight_no': [], 'atis_ground_fare': [], 'atis_flight_time': [], 'atis_flight#atis_airfare': [], 'atis_distance': [], 'atis_aircraft': [], 'atis_capacity': [], 'default': ['default message'], 'goodbye': ['goodbye for now'], 'greet': ['Hello you! :)'], 'thankyou': ['you are very welcome']}\n"
     ]
    }
   ],
   "source": [
    "# criar dicionarios para guardar as respostas por intent.\n",
    "# criar alguns intents basicos greetings...\n",
    "\n",
    "#templates\n",
    "user_template = \"USER : {0}\" \n",
    "bot_template = \"BOT : {0}\"\n",
    "\n",
    "dict_atis = dict_Labels\n",
    "\n",
    "# keywords para identificar padrões de intents basicos\n",
    "keywords = {'greet': ['hello', 'hi', 'hey'],\n",
    "            'goodbye': ['bye', 'farewell'],\n",
    "            'thankyou': ['thank', 'thx']}\n",
    "\n",
    "# intents são chaves do dicionario e o valor são as respostas\n",
    "responses = {'default': 'default message',\n",
    "             'goodbye': 'goodbye for now',\n",
    "             'greet': 'Hello you! :)',\n",
    "             'thankyou': 'you are very welcome'}\n",
    "\n",
    "# Novo dicionario de respostas do bot\n",
    "update_responses = {}\n",
    "\n",
    "for intent, value in dict_Labels.items():\n",
    "    if (intent not in update_responses):\n",
    "        update_responses[intent] = []\n",
    "\n",
    "for intent,resposta in responses.items():\n",
    "    if intent not in update_responses:\n",
    "        update_responses[intent] = [resposta]\n",
    "\n",
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    \n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "    \n",
    "# Print the dicionarios\n",
    "print(patterns)\n",
    "print(responses)\n",
    "print(update_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : Hello you! :)\n",
      "USER : Flight from NY\n",
      "BOT : default message\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    \n",
    "    # para intents dentro do dicionario de padões\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if re.search(pattern, message) is not None:\n",
    "            matched_intent = intent\n",
    "\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    \n",
    "    intent = None\n",
    "    # Call the match_intent function\n",
    "    if(match_intent(message) is not None):\n",
    "        intent = match_intent(message)\n",
    "    else:\n",
    "        listaIntent = Intent(message,model1)\n",
    "        intent = listaIntent[0]\n",
    "        #print(intent)\n",
    "        \n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in update_responses:\n",
    "        if len(update_responses[intent]) != 0:\n",
    "            key = intent\n",
    "    resposta = random.choice(update_responses[key])\n",
    "    \n",
    "    return resposta\n",
    "\n",
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "\n",
    "send_message(\"Flight from NY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    while True:\n",
    "        message = input(\"Send Message: \")\n",
    "        if(message == 'exit'):\n",
    "            break\n",
    "        else:\n",
    "            send_message(message)\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the coach flights between dallas and baltimore leaving august tenth and returning august twelve\n"
     ]
    }
   ],
   "source": [
    "sentence = atis_1_test['tokens'][0]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">what are the coach flights between \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dallas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    baltimore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " leaving \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    august tenth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and returning \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    august twelve\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"01c17ea077974be28b06c50983d31cdb-0\" class=\"displacy\" width=\"1650\" height=\"387.0\" direction=\"ltr\" style=\"max-width: none; height: 387.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">what</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">coach</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">flights</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">between</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">dallas</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">baltimore</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">leaving</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">august</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">tenth</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">returning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">august</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">twelve</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-0\" stroke-width=\"2px\" d=\"M70,252.0 C70,202.0 130.0,202.0 130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,254.0 L62,242.0 78,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-1\" stroke-width=\"2px\" d=\"M270,252.0 C270,152.0 435.0,152.0 435.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,254.0 L262,242.0 278,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-2\" stroke-width=\"2px\" d=\"M370,252.0 C370,202.0 430.0,202.0 430.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,254.0 L362,242.0 378,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-3\" stroke-width=\"2px\" d=\"M170,252.0 C170,102.0 440.0,102.0 440.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M440.0,254.0 L448.0,242.0 432.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-4\" stroke-width=\"2px\" d=\"M470,252.0 C470,202.0 530.0,202.0 530.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M530.0,254.0 L538.0,242.0 522.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-5\" stroke-width=\"2px\" d=\"M570,252.0 C570,202.0 630.0,202.0 630.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630.0,254.0 L638.0,242.0 622.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-6\" stroke-width=\"2px\" d=\"M670,252.0 C670,202.0 730.0,202.0 730.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730.0,254.0 L738.0,242.0 722.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-7\" stroke-width=\"2px\" d=\"M670,252.0 C670,152.0 835.0,152.0 835.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M835.0,254.0 L843.0,242.0 827.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-8\" stroke-width=\"2px\" d=\"M470,252.0 C470,2.0 950.0,2.0 950.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,254.0 L958.0,242.0 942.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-9\" stroke-width=\"2px\" d=\"M970,252.0 C970,202.0 1030.0,202.0 1030.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030.0,254.0 L1038.0,242.0 1022.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-10\" stroke-width=\"2px\" d=\"M970,252.0 C970,152.0 1135.0,152.0 1135.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1135.0,254.0 L1143.0,242.0 1127.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-11\" stroke-width=\"2px\" d=\"M970,252.0 C970,102.0 1240.0,102.0 1240.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1240.0,254.0 L1248.0,242.0 1232.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-12\" stroke-width=\"2px\" d=\"M970,252.0 C970,52.0 1345.0,52.0 1345.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1345.0,254.0 L1353.0,242.0 1337.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-13\" stroke-width=\"2px\" d=\"M1370,252.0 C1370,202.0 1430.0,202.0 1430.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1430.0,254.0 L1438.0,242.0 1422.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-01c17ea077974be28b06c50983d31cdb-0-14\" stroke-width=\"2px\" d=\"M1470,252.0 C1470,202.0 1530.0,202.0 1530.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-01c17ea077974be28b06c50983d31cdb-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1530.0,254.0 L1538.0,242.0 1522.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent',jupyter=True)\n",
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+\" - \"+str(ent.start_char)+\" - \"+str(ent.end_char)+\" - \"+ent.label_+\" - \"+\n",
    "                 str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print(\"No named entities found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dallas - 35 - 41 - GPE - Countries, cities, states\n",
      "baltimore - 46 - 55 - GPE - Countries, cities, states\n",
      "august tenth - 64 - 76 - DATE - Absolute or relative dates or periods\n",
      "august twelve - 91 - 104 - DATE - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
